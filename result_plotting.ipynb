{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.reproduce_utils import Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(methods, metrics, dataset_names, result_df):\n",
    "    headers = [\"metric\", \"dataset\"]\n",
    "    indices = [\n",
    "        \"method\",\n",
    "        \"seed\",\n",
    "    ]\n",
    "    columns = pd.MultiIndex.from_product([metrics, dataset_names], names=headers)\n",
    "    index = pd.MultiIndex.from_product([methods, [1]], names=indices)\n",
    "    df = pd.DataFrame(columns=columns, index=index)\n",
    "    df.sort_index(inplace=True)\n",
    "    for index, row in result_df.iterrows():\n",
    "        for method in methods:\n",
    "            if int(row[\"dataset_id\"]) not in dataset_names:\n",
    "                continue\n",
    "            if \"logistic\" in method:\n",
    "                score_method = \"linear\"\n",
    "            else:\n",
    "                score_method = method\n",
    "            row_id = (method, 1)\n",
    "            col = (\"acc\", row[\"dataset_id\"])\n",
    "            df.loc[row_id, col] = row[f\"score_{score_method}\"]\n",
    "    return Results(df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_rank_table(results: Results):\n",
    "    datasets = results.datasets\n",
    "    metrics = sorted(results.metrics, reverse=True)\n",
    "    # print(results.methods)\n",
    "    df = results.df\n",
    "    results_rank = {}\n",
    "    results_score = {}\n",
    "    for metric in metrics:\n",
    "        if \"time\" in metric:\n",
    "            continue\n",
    "        metric_df = df[metric]\n",
    "        dataset_rank_dfs = []\n",
    "        dataset_mean_dfs = []\n",
    "        for dataset in datasets:\n",
    "            if dataset not in metric_df.columns:\n",
    "                continue\n",
    "            dataset_rank_df = metric_df[dataset].groupby('method').mean().rank(ascending=False)\n",
    "            dataset_rank_dfs.append(dataset_rank_df)\n",
    "            dataset_mean_dfs.append(metric_df[dataset])\n",
    "\n",
    "        results_rank[metric] = pd.concat(dataset_rank_dfs).groupby(\"method\").mean()\n",
    "        \n",
    "        results_score[metric] = pd.concat(dataset_mean_dfs).groupby(\"method\").mean()\n",
    "    score_df = pd.DataFrame(results_score).reset_index()\n",
    "    rank_df = pd.DataFrame(results_rank).reset_index()\n",
    "    final_table = rank_df.merge(score_df, on=\"method\", suffixes=[\" Mean Rank\", \" Mean Score\"]).T\n",
    "    final_table.columns = final_table.iloc[0]\n",
    "    final_table = final_table.iloc[1:]\n",
    "    return final_table\n",
    "\n",
    "def pprint(df):\n",
    "    for column in df:\n",
    "        df[column] = df[column].astype('float').round(decimals=4)\n",
    "\n",
    "    print(df.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"rf\", \"tree\", \"mlp\", \"hgbt\", \"logistic\"]\n",
    "metrics = [\"acc\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "too_easy_result_df = pd.read_csv(\"too_easy_without_resnet.csv\").drop([\"Unnamed: 0\"], axis=1)\n",
    "too_easy_dataset_names = too_easy_result_df[\"dataset_id\"].astype(int).copy().to_list()\n",
    "too_easy_result = get_result(methods, metrics, too_easy_dataset_names, too_easy_result_df)\n",
    "too_easy_all_datasets_ranks = get_average_rank_table(too_easy_result)\n",
    "\n",
    "selected_result_df = pd.read_csv(\"benchmark_without_resnet.csv\").drop([\"Unnamed: 0\"], axis=1)\n",
    "selected_dataset_names = selected_result_df[\"dataset_id\"].astype(int).copy().to_list()\n",
    "selected_result = get_result(methods, metrics, selected_dataset_names, selected_result_df)\n",
    "selected_all_datasets_ranks = get_average_rank_table(selected_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n\\n\\nToo easy ({len(too_easy_dataset_names)} datasets from latest csv)\")\n",
    "pprint(too_easy_all_datasets_ranks)\n",
    "print(\"\\n\\n\\ngrinzstjan et al\")\n",
    "pprint(selected_all_datasets_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_result = Results(pd.concat([too_easy_result.df, selected_result.df]))\n",
    "all_result_ranks = get_average_rank_table(all_result)\n",
    "print(f\"\\nToo easy ({len(too_easy_dataset_names)} datasets from latest csv) + grinzstjan et al\")\n",
    "pprint(all_result_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "too_easy_result_df.to_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Datasets tabular data benchmark - Feuille 12.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "too_easy_result_df = pd.read_csv(\"too_easy_without_resnet.csv\").drop([\"Unnamed: 0\"], axis=1)\n",
    "too_easy_dataset_names = too_easy_result_df[\"dataset_id\"].copy().to_list()\n",
    "too_easy_result = get_result(methods, metrics, too_easy_dataset_names, too_easy_result_df)\n",
    "too_easy_all_datasets_ranks = get_average_rank_table(too_easy_result)\n",
    "too_easy_dids = []\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        if not pd.isnull(row[\"dataset_id\"]) and row[\"Remove\"] != 1 and (row[\"too_easy\"] == 1 or args.all) and row[\"Redundant\"] != 1:\n",
    "            prefix_to_skip = [\"BNG\", \"RandomRBF\", \"GTSRB\", \"CovPokElec\", \"PCam\"]\n",
    "            if not (np.any([row[\"dataset_name\"].startswith(prefix) for prefix in\n",
    "                            prefix_to_skip]) or \"mnist\" in row[\"dataset_name\"].lower() or \"image\" in row[\n",
    "                        \"dataset_name\"].lower() or \"cifar\" in row[\"dataset_name\"].lower() or row[\"dataset_id\"] == 1414):\n",
    "                        too_easy_dids.append(int(row[\"dataset_id\"]))\n",
    "    except:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(too_easy_dids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(too_easy_dataset_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_datasets_info = pd.read_csv(\"Datasets tabular data benchmark - numerical_classif-3.csv\").fillna(0)\n",
    "\n",
    "real_too_easy_dataset_ids = []\n",
    "for index, row in full_datasets_info.iterrows():\n",
    "    if not int(row[\"too_easy\"]) and int(row[\"dataset_id\"]) != 0:\n",
    "        real_too_easy_dataset_ids.append(int(row[\"dataset_id\"]))\n",
    "        # print(row[\"dataset_id\"])\n",
    "real_too_easy_dataset_ids\n",
    "full_datasets_info[~full_datasets_info[\"dataset_id\"].isin(real_too_easy_dataset_ids)][\"dataset_id\"].astype(int).to_numpy()\n",
    "full_datasets_info[~full_datasets_info[\"dataset_id\"].isin(real_too_easy_dataset_ids)][\"dataset_id\"].astype(int).to_numpy()\n",
    "my_results = pd.read_csv(\"csv_files/new_too_easy_without_resnet_numerical.csv\").fillna(0)\n",
    "\n",
    "full_datasets_info[\"score_hgbt\"] = full_datasets_info[\"score_hbgt\"].str.replace(',', '.').astype(float)\n",
    "full_datasets_info[\"score_linear\"] = full_datasets_info[\"score_logistic\"].str.replace(',', '.').astype(float)\n",
    "leo_results_required = full_datasets_info[full_datasets_info[\"dataset_id\"].isin(real_too_easy_dataset_ids)][[\"score_hgbt\", \"score_linear\"]].astype(float)\n",
    "leo_results_required = leo_results_required.reindex(range(leo_results_required.shape[0]))\n",
    "my_results_required = my_results[my_results[\"dataset_id\"].isin(real_too_easy_dataset_ids)][[\"score_hgbt\", \"score_linear\"]].astype(float)\n",
    "my_results_required = my_results_required.reindex(range(leo_results_required.shape[0]))\n",
    "(my_results_required['score_hgbt'] - 1.05 * my_results_required['score_linear'] > 0)\n",
    "diff = my_results_required - leo_results_required \n",
    "leo_results_required.plot(kind=\"box\")\n",
    "\n",
    "\n",
    "\n",
    "diff.median(axis=0)\n",
    "diff.plot(kind=\"box\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_without_resnet_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "too_easy_without_resnet = pd.read_csv(\"csv_files/new_too_easy_without_resnet_numerical.csv\", index_col=None).fillna(0)\n",
    "benchmark_without_resnet = pd.read_csv(\"csv_files/benchmark_without_resnet.csv\", index_col=None).fillna(0)\n",
    "too_easy_resnet = pd.read_csv(\"csv_files/new_too_easy_resnet_numerical_60_0.csv\", index_col=None).fillna(0)\n",
    "too_easy_resnet_2 = pd.read_csv(\"csv_files/new_too_easy_resnet_numerical_60_1.csv\", index_col=None).fillna(0)\n",
    "benchmark_numerical_resnet = pd.read_csv(\"csv_files/benchmark_resnet_numerical.csv\", index_col=None).fillna(0)\n",
    "# benchmark_categorical_r = pd.read_csv(\"csv_files/new_too_easy_without_resnet_numerical.csv\").fillna(0)\n",
    "\n",
    "too_easy_resnet = pd.concat([too_easy_resnet, too_easy_resnet_2])\n",
    "benchmark_without_resnet_numerical = benchmark_without_resnet[benchmark_without_resnet[\"dataset_id\"].isin(benchmark_numerical_resnet[\"dataset_id\"].to_list())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_results = benchmark_without_resnet_numerical.set_index(\"dataset_id\").copy()\n",
    "benchmark_results[\"score_resnet\"] = benchmark_numerical_resnet.set_index(\"dataset_id\")[\"score_resnet\"]\n",
    "\n",
    "too_easy_results = too_easy_without_resnet.set_index(\"dataset_id\").copy()\n",
    "too_easy_results[\"score_resnet\"] = too_easy_resnet.set_index(\"dataset_id\")[\"score_resnet\"]\n",
    "\n",
    "\n",
    "benchmark_ids = benchmark_numerical_resnet[\"dataset_id\"].to_list()\n",
    "too_easy_dataset_ids = too_easy_resnet[\"dataset_id\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [ \"hgbt\", \"logistic\"] # , \"resnet\"] # \"rf\", \"tree\", \"mlp\",\n",
    "metrics = [\"acc\"]\n",
    "\n",
    "too_easy_result = get_result(methods, metrics, too_easy_dataset_ids, too_easy_results.reset_index())\n",
    "too_easy_all_datasets_ranks = get_average_rank_table(too_easy_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "too_easy_all_datasets_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_result = get_result(methods, metrics, benchmark_ids, benchmark_results.reset_index())\n",
    "benchmark_datasets_ranks = get_average_rank_table(benchmark_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_datasets_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"hgbt\", \"logistic\"]\n",
    "metrics = [\"acc\"]\n",
    "full_datasets_info = pd.read_csv(\"Datasets tabular data benchmark - numerical_classif-3.csv\").fillna(0)\n",
    "full_datasets_info[\"score_hgbt\"] = full_datasets_info[\"score_hbgt\"].str.replace(',', '.').astype(float)\n",
    "full_datasets_info[\"score_linear\"] = full_datasets_info[\"score_logistic\"].str.replace(',', '.').astype(float)\n",
    "\n",
    "too_easy_their_result = get_result(methods, metrics, too_easy_dataset_ids, full_datasets_info)\n",
    "too_easy_their_results_ranks = get_average_rank_table(too_easy_their_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(too_easy_result.datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "too_easy_their_results_ranks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_their_result = get_result(methods, metrics, benchmark_ids, full_datasets_info)\n",
    "benchmark_their_results_ranks = get_average_rank_table(benchmark_their_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_their_results_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_my_results = pd.concat([too_easy_results, benchmark_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_my_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'methods' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/rkohli/tabular-benchmark/result_plotting.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bkisbat1/home/rkohli/tabular-benchmark/result_plotting.ipynb#Y103sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m all_result \u001b[39m=\u001b[39m get_result(methods, metrics, benchmark_ids\u001b[39m+\u001b[39mtoo_easy_dataset_ids, all_my_results\u001b[39m.\u001b[39mreset_index())\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkisbat1/home/rkohli/tabular-benchmark/result_plotting.ipynb#Y103sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m all_results_ranks \u001b[39m=\u001b[39m get_average_rank_table(all_result)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'methods' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "all_result = get_result(methods, metrics, benchmark_ids+too_easy_dataset_ids, all_my_results.reset_index())\n",
    "all_results_ranks = get_average_rank_table(all_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = all_my_results[\"score_hgbt\"] < 1.05 * all_my_results[\"score_linear\"] \n",
    "y = all_my_results[\"score_resnet\"] < 1.05 * all_my_results[\"score_linear\"]\n",
    "their_selection_criteria = [a and b for a, b in zip(x, y)]\n",
    "too_easy_on_my_dataset_ids_their_selection_criteria = all_my_results.loc[their_selection_criteria].index.to_list()\n",
    "select_on_my_dataset_ids_their = all_my_results.loc[list(map(lambda x: not x, their_selection_criteria))].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = all_my_results[\"score_hgbt\"] < 1.05 * all_my_results[\"score_tree\"] \n",
    "y = all_my_results[\"score_resnet\"] < 1.05 * all_my_results[\"score_tree\"]\n",
    "tree_selection_criteria = [a and b for a, b in zip(x, y)]\n",
    "too_easy_on_my_dataset_ids_tree_selection_criteria = all_my_results.loc[tree_selection_criteria].index.to_list()\n",
    "select_on_my_dataset_ids_tree = all_my_results.loc[list(map(lambda x: not x, tree_selection_criteria))].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(select_on_my_dataset_ids_their)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [ \"hgbt\", \"logistic\", \"resnet\", \"rf\", \"tree\", \"mlp\",]\n",
    "metrics = [\"acc\"]\n",
    "too_easy_on_my_result = get_result(methods, metrics, too_easy_on_my_dataset_ids_their_selection_criteria, all_my_results.reset_index())\n",
    "too_easy_on_my_ranks = get_average_rank_table(too_easy_on_my_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [ \"hgbt\", \"logistic\", \"resnet\", \"rf\", \"tree\", \"mlp\",]\n",
    "metrics = [\"acc\"]\n",
    "select_on_my_result = get_result(methods, metrics, select_on_my_dataset_ids_their, all_my_results.reset_index())\n",
    "select_on_my_ranks = get_average_rank_table(select_on_my_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>method</th>\n",
       "      <th>hgbt</th>\n",
       "      <th>logistic</th>\n",
       "      <th>mlp</th>\n",
       "      <th>resnet</th>\n",
       "      <th>rf</th>\n",
       "      <th>tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc Mean Rank</th>\n",
       "      <td>1.554348</td>\n",
       "      <td>5.01087</td>\n",
       "      <td>3.141304</td>\n",
       "      <td>3.902174</td>\n",
       "      <td>2.206522</td>\n",
       "      <td>5.184783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc Mean Score</th>\n",
       "      <td>0.74858</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.725965</td>\n",
       "      <td>0.616807</td>\n",
       "      <td>0.742845</td>\n",
       "      <td>0.680823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "method              hgbt  logistic       mlp    resnet        rf      tree\n",
       "acc Mean Rank   1.554348   5.01087  3.141304  3.902174  2.206522  5.184783\n",
       "acc Mean Score   0.74858  0.682315  0.725965  0.616807  0.742845  0.680823"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_on_my_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>method</th>\n",
       "      <th>hgbt</th>\n",
       "      <th>logistic</th>\n",
       "      <th>mlp</th>\n",
       "      <th>resnet</th>\n",
       "      <th>rf</th>\n",
       "      <th>tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc Mean Rank</th>\n",
       "      <td>2.155914</td>\n",
       "      <td>3.66129</td>\n",
       "      <td>2.72043</td>\n",
       "      <td>3.698925</td>\n",
       "      <td>3.134409</td>\n",
       "      <td>5.629032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc Mean Score</th>\n",
       "      <td>0.845653</td>\n",
       "      <td>0.836374</td>\n",
       "      <td>0.841734</td>\n",
       "      <td>0.821575</td>\n",
       "      <td>0.838758</td>\n",
       "      <td>0.796502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "method              hgbt  logistic       mlp    resnet        rf      tree\n",
       "acc Mean Rank   2.155914   3.66129   2.72043  3.698925  3.134409  5.629032\n",
       "acc Mean Score  0.845653  0.836374  0.841734  0.821575  0.838758  0.796502"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "too_easy_on_my_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [ \"hgbt\", \"logistic\", \"resnet\", \"rf\", \"tree\", \"mlp\",]\n",
    "metrics = [\"acc\"]\n",
    "too_easy_on_my_result_tree = get_result(methods, metrics, too_easy_on_my_dataset_ids_tree_selection_criteria, all_my_results.reset_index())\n",
    "too_easy_on_my_ranks_tree = get_average_rank_table(too_easy_on_my_result_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [ \"hgbt\", \"logistic\", \"resnet\", \"rf\", \"tree\", \"mlp\",]\n",
    "metrics = [\"acc\"]\n",
    "select_on_my_result_tree = get_result(methods, metrics, select_on_my_dataset_ids_tree, all_my_results.reset_index())\n",
    "select_on_my_ranks_tree = get_average_rank_table(select_on_my_result_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>method</th>\n",
       "      <th>hgbt</th>\n",
       "      <th>logistic</th>\n",
       "      <th>mlp</th>\n",
       "      <th>resnet</th>\n",
       "      <th>rf</th>\n",
       "      <th>tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc Mean Rank</th>\n",
       "      <td>1.690217</td>\n",
       "      <td>4.168478</td>\n",
       "      <td>2.918478</td>\n",
       "      <td>3.625</td>\n",
       "      <td>2.918478</td>\n",
       "      <td>5.679348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc Mean Score</th>\n",
       "      <td>0.764519</td>\n",
       "      <td>0.728615</td>\n",
       "      <td>0.749975</td>\n",
       "      <td>0.689699</td>\n",
       "      <td>0.753759</td>\n",
       "      <td>0.688339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "method              hgbt  logistic       mlp    resnet        rf      tree\n",
       "acc Mean Rank   1.690217  4.168478  2.918478     3.625  2.918478  5.679348\n",
       "acc Mean Score  0.764519  0.728615  0.749975  0.689699  0.753759  0.688339"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_on_my_ranks_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>method</th>\n",
       "      <th>hgbt</th>\n",
       "      <th>logistic</th>\n",
       "      <th>mlp</th>\n",
       "      <th>resnet</th>\n",
       "      <th>rf</th>\n",
       "      <th>tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc Mean Rank</th>\n",
       "      <td>2.478723</td>\n",
       "      <td>3.989362</td>\n",
       "      <td>2.744681</td>\n",
       "      <td>4.042553</td>\n",
       "      <td>2.648936</td>\n",
       "      <td>5.095745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc Mean Score</th>\n",
       "      <td>0.909462</td>\n",
       "      <td>0.896527</td>\n",
       "      <td>0.908041</td>\n",
       "      <td>0.879303</td>\n",
       "      <td>0.911267</td>\n",
       "      <td>0.895006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "method              hgbt  logistic       mlp    resnet        rf      tree\n",
       "acc Mean Rank   2.478723  3.989362  2.744681  4.042553  2.648936  5.095745\n",
       "acc Mean Score  0.909462  0.896527  0.908041  0.879303  0.911267  0.895006"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "too_easy_on_my_ranks_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('tab_bench-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bdd89d8741d58698331340ea54180aeeb25ca9f979bf53364921e9917b5aca39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
