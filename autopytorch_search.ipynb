{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.reproduce_utils import Results\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(methods, metrics, dataset_names, result_df):\n",
    "    headers = [\"metric\", \"dataset\"]\n",
    "    indices = [\n",
    "        \"method\",\n",
    "        \"seed\",\n",
    "    ]\n",
    "    columns = pd.MultiIndex.from_product([metrics, dataset_names], names=headers)\n",
    "    index = pd.MultiIndex.from_product([methods, [1]], names=indices)\n",
    "    df = pd.DataFrame(columns=columns, index=index)\n",
    "    df.sort_index(inplace=True)\n",
    "    for index, row in result_df.iterrows():\n",
    "        for method in methods:\n",
    "            if int(row[\"dataset_id\"]) not in dataset_names:\n",
    "                continue\n",
    "            if \"logistic\" in method:\n",
    "                score_method = \"linear\"\n",
    "            else:\n",
    "                score_method = method\n",
    "            row_id = (method, 1)\n",
    "            col = (\"acc\", row[\"dataset_id\"])\n",
    "            df.loc[row_id, col] = row[f\"score_{score_method}\"]\n",
    "    return Results(df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autopytorch_cocktails_random_df = pd.read_csv('csv_files/cocktails_random_refit_results.csv', index_col=0)\n",
    "# autopytorch_cocktails_random_df['dataset_id'] = autopytorch_cocktails_random_df['dataset_id'].astype(int).replace(dict(zip(final_benchmark_dataset_ids, selected_datasets)))\n",
    "# autopytorch_cocktails_random_df = autopytorch_cocktails_random_df.set_index('dataset_id')\n",
    "# all_my_results['score_cocktails_random'] = autopytorch_cocktails_random_df['test_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_my_results = pd.read_csv(\"csv_files/final_all_my_results.csv\", index_col=None).set_index(\"dataset_id\").sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cocktails_default_df = pd.read_csv(\"csv_files/cocktails_default_refit_results.csv\", index_col=None).set_index('dataset_id')\n",
    "# all_my_results = pd.read_csv(\"csv_files/all_results_with_cocktail_random.csv\", index_col=\"dataset_id\").sort_index()\n",
    "# all_my_results[\"score_cocktails_default\"] = cocktails_default_df['test_score']\n",
    "# all_my_results[\"score_autopytorch_default\"] = scores_autopytorch_default['autopytorch_master_default']\n",
    "# all_my_results[\"score_cocktails\"] = cocktails_df['test_score']\n",
    "# all_my_results.columns\n",
    "# all_my_results = all_my_results.drop(\"score_autopytorch_default\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_rank_table(results: Results):\n",
    "    datasets = results.datasets\n",
    "    metrics = sorted(results.metrics, reverse=True)\n",
    "    # print(results.methods)\n",
    "    df = results.df\n",
    "    results_rank = {}\n",
    "    results_score = {}\n",
    "    for metric in metrics:\n",
    "        if \"time\" in metric:\n",
    "            continue\n",
    "        metric_df = df[metric]\n",
    "        dataset_rank_dfs = []\n",
    "        dataset_mean_dfs = []\n",
    "        for dataset in datasets:\n",
    "            if dataset not in metric_df.columns:\n",
    "                continue\n",
    "            dataset_rank_df = metric_df[dataset].groupby('method').mean().rank(ascending=False)\n",
    "            dataset_rank_dfs.append(dataset_rank_df)\n",
    "            dataset_mean_dfs.append(metric_df[dataset])\n",
    "\n",
    "        results_rank[metric.upper()] = pd.concat(dataset_rank_dfs).groupby(\"method\").mean()\n",
    "        \n",
    "        results_score[metric.upper()] = pd.concat(dataset_mean_dfs).groupby(\"method\").mean()\n",
    "    score_df = pd.DataFrame(results_score).reset_index()\n",
    "    rank_df = pd.DataFrame(results_rank).reset_index()\n",
    "    final_table = rank_df.merge(score_df, on=\"method\", suffixes=[\" Mean Rank\", \" Mean Score\"]).T\n",
    "    final_table.columns = final_table.iloc[0]\n",
    "    final_table = final_table.iloc[1:]\n",
    "    return final_table\n",
    "\n",
    "def pprint(df):\n",
    "    for column in df:\n",
    "        df[column] = df[column].astype('float').round(decimals=4)\n",
    "\n",
    "    print(df.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_too_easy_select_acc_to_difference(df: pd.DataFrame, methods: list, stddev: float = 0.05):\n",
    "    std_datasets = df[[f\"score_{method}\" for method in methods]].std(axis=1)\n",
    "    selection_criteria = std_datasets < stddev\n",
    "    too_easy_on_selection_criteria = df.loc[selection_criteria].index.to_list()\n",
    "    select_on_selection_criteria = df.loc[list(map(lambda x: not x, selection_criteria))].index.to_list()\n",
    "    return too_easy_on_selection_criteria, select_on_selection_criteria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_too_easy_select_acc_to_criteria(df: pd.DataFrame, better_methods: list, worse_methods: list):\n",
    "        \n",
    "    lhs = df[better_methods].max(axis=1) if len(better_methods) > 1 else df[better_methods[0]]\n",
    "    rhs = df[worse_methods].max(axis=1) if len(worse_methods) > 1 else df[worse_methods[0]]\n",
    "    selection_criteria = lhs < 1.05 * rhs\n",
    "    too_easy_on_selection_criteria = df.loc[selection_criteria].index.to_list()\n",
    "    select_on_selection_criteria = df.loc[list(map(lambda x: not x, selection_criteria))].index.to_list()\n",
    "    return too_easy_on_selection_criteria, select_on_selection_criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "too_easy_cocktails_default_hgbt_linear_dids, select_cocktails_default_hgbt_linear_dids = get_too_easy_select_acc_to_criteria(all_my_results, better_methods=[\"score_hgbt\", \"score_cocktails_default\"], worse_methods=[\"score_linear\"])\n",
    "too_easy_cocktails_default_hgbt_tree_dids, select_cocktails_default_hgbt_tree_dids = get_too_easy_select_acc_to_criteria(all_my_results, better_methods=[\"score_hgbt\", \"score_cocktails_default\"], worse_methods=[\"score_tree\"])\n",
    "too_easy_cocktails_default_hgbt_combined_dids, select_cocktails_default_hgbt_combined_dids = get_too_easy_select_acc_to_criteria(all_my_results, better_methods=[\"score_hgbt\", \"score_cocktails_default\"], worse_methods=[\"score_tree\", \"score_linear\"])\n",
    "too_easy_hgbt_tree_dids, select_hgbt_tree_dids = get_too_easy_select_acc_to_criteria(all_my_results, better_methods=[\"score_hgbt\"], worse_methods=[\"score_tree\"])\n",
    "too_easy_hgbt_linear_dids, select_hgbt_linear_dids = get_too_easy_select_acc_to_criteria(all_my_results, better_methods=[\"score_hgbt\"], worse_methods=[\"score_linear\"])\n",
    "too_easy_hgbt_combined_dids, select_hgbt_combined_dids = get_too_easy_select_acc_to_criteria(all_my_results, better_methods=[\"score_hgbt\"], worse_methods=[\"score_tree\", \"score_linear\"])\n",
    "too_easy_resnet_tree_dids, select_resnet_tree_dids = get_too_easy_select_acc_to_criteria(all_my_results, better_methods=[\"score_resnet\"], worse_methods=[\"score_tree\"])\n",
    "too_easy_mlp_tree_dids, select_mlp_tree_dids = get_too_easy_select_acc_to_criteria(all_my_results, better_methods=[\"score_mlp\"], worse_methods=[\"score_tree\"])\n",
    "too_easy_cocktails_default_tree_dids, select_cocktails_default_tree_dids = get_too_easy_select_acc_to_criteria(all_my_results, better_methods=[\"score_cocktails_default\"], worse_methods=[\"score_tree\"])\n",
    "too_easy_autopytorch_default_cocktails_default_hgbt_combined_dids, select_autopytorch_default_cocktails_default_hgbt_combined_dids = get_too_easy_select_acc_to_criteria(all_my_results, better_methods=[\"score_hgbt\", \"score_cocktails_default\"], worse_methods=[\"score_linear\", \"score_tree\"])\n",
    "too_easy_cocktails_default_linear_dids, select_cocktails_default_linear_dids = get_too_easy_select_acc_to_criteria(all_my_results, better_methods=[\"score_cocktails_default\"], worse_methods=[\"score_linear\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ranks_df = {\n",
    "    # results vs logreg\n",
    "    # \"too_easy_(HGBT,_Cocktails_default)_vs_(Logreg)_on_my\": {\n",
    "    #     \"ranks\": None,\n",
    "    #     \"dids\": too_easy_cocktails_default_hgbt_linear_dids},\n",
    "    \"select_(HGBT,_Cocktails_default)_vs_(Logreg)_on_my\": {\n",
    "        \"ranks\": None,\n",
    "        \"dids\": select_cocktails_default_hgbt_linear_dids},\n",
    "\n",
    "    # results vs tree\n",
    "    # \"too_easy_(HGBT,_Cocktails_default)_vs_(tree)_on_my\": {\n",
    "    #     \"ranks\": None,\n",
    "    #     \"dids\": too_easy_cocktails_default_hgbt_tree_dids},\n",
    "    \"select_(HGBT,_Cocktails_default)_vs_(tree)_on_my\": {\n",
    "        \"ranks\": None,\n",
    "        \"dids\": select_cocktails_default_hgbt_tree_dids},\n",
    "    \n",
    "    # results vs both\n",
    "    # \"too_easy_(HGBT,_Cocktails_default)_vs_(tree,Logreg)_on_my\": {\n",
    "    #     \"ranks\": None,\n",
    "    #     \"dids\": too_easy_cocktails_default_hgbt_combined_dids},\n",
    "    \"select_(HGBT,_Cocktails_default)_vs_(tree,Logreg)_on_my\": {\n",
    "        \"ranks\": None,\n",
    "        \"dids\": select_cocktails_default_hgbt_combined_dids},\n",
    "\n",
    "    # results individual\n",
    "    # vs tree\n",
    "    # \"too_easy_(_Cocktails_default)_vs_(tree)_on_my\": {\n",
    "    #     \"ranks\": None,\n",
    "    #     \"dids\": too_easy_cocktails_default_tree_dids},\n",
    "    \"select_(_Cocktails_default)_vs_(tree)_on_my\": {\n",
    "        \"ranks\": None,\n",
    "        \"dids\": select_cocktails_default_tree_dids},\n",
    "    # vs logreg\n",
    "    # \"too_easy_(_Cocktails_default)_vs_(Logreg)_on_my\": {\n",
    "    #     \"ranks\": None,\n",
    "    #     \"dids\": too_easy_cocktails_default_linear_dids},\n",
    "    \"select_(_Cocktails_default)_vs_(Logreg)_on_my\": {\n",
    "        \"ranks\": None,\n",
    "        \"dids\": select_cocktails_default_linear_dids},\n",
    "\n",
    "    # all combined\n",
    "    # \"too_easy_(HGBT,_Cocktails_default)_vs_(tree,Logreg)_on_my\": {\n",
    "    #     \"ranks\": None,\n",
    "    #     \"dids\": too_easy_autopytorch_default_cocktails_default_hgbt_combined_dids},\n",
    "    \"select_(HGBT,_Cocktails_default)_vs_(tree,Logreg)_on_my\": {\n",
    "        \"ranks\": None,\n",
    "        \"dids\": select_autopytorch_default_cocktails_default_hgbt_combined_dids},\n",
    "\n",
    "    # from previous tables\n",
    "    # \"too_easy_(HGBT)_vs_(tree)_on_my\": {\n",
    "    #     \"ranks\": None,\n",
    "    #     \"dids\": too_easy_hgbt_tree_dids},\n",
    "    \"select_(HGBT)_vs_(tree)_on_my\": {\n",
    "        \"ranks\": None,\n",
    "        \"dids\": select_hgbt_tree_dids},\n",
    "    # \"too_easy_(HGBT)_vs_(Logreg)_on_my\": {\n",
    "    #     \"ranks\": None,\n",
    "    #     \"dids\": too_easy_hgbt_linear_dids},\n",
    "    \"select_(HGBT)_vs_(Logreg)_on_my\": {\n",
    "        \"ranks\": None,\n",
    "        \"dids\": select_hgbt_linear_dids},\n",
    "    # \"too_easy_(HGBT)_vs_(tree,Logreg)_on_my\": {\n",
    "    #     \"ranks\": None,\n",
    "    #     \"dids\": too_easy_hgbt_combined_dids},\n",
    "    \"select_(HGBT)_vs_(tree,Logreg)_on_my\": {\n",
    "        \"ranks\": None,\n",
    "        \"dids\": select_hgbt_combined_dids},\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SELECT (HGBT, COCKTAILS DEFAULT) VS (LOGREG) ON MY (19)\n",
      "|                |   cocktails_default |   cocktails_random |   hgbt |   logistic |\n",
      "|:---------------|--------------------:|-------------------:|-------:|-----------:|\n",
      "| ACC Mean Rank  |              2.4211 |             2.2778 | 1.4211 |     3.7895 |\n",
      "| ACC Mean Score |              0.7771 |             0.7788 | 0.7952 |     0.7042 |\n",
      "\n",
      "\n",
      "SELECT (HGBT, COCKTAILS DEFAULT) VS (TREE) ON MY (44)\n",
      "|                |   cocktails_default |   cocktails_random |   hgbt |   logistic |\n",
      "|:---------------|--------------------:|-------------------:|-------:|-----------:|\n",
      "| ACC Mean Rank  |              2.7045 |             2.2927 | 1.8182 |     3.0682 |\n",
      "| ACC Mean Score |              0.7668 |             0.7782 | 0.7781 |     0.7441 |\n",
      "\n",
      "\n",
      "SELECT (HGBT, COCKTAILS DEFAULT) VS (TREE,LOGREG) ON MY (15)\n",
      "|                |   cocktails_default |   cocktails_random |   hgbt |   logistic |\n",
      "|:---------------|--------------------:|-------------------:|-------:|-----------:|\n",
      "| ACC Mean Rank  |              2.3333 |             2.2857 | 1.5333 |     3.7333 |\n",
      "| ACC Mean Score |              0.7567 |             0.7627 | 0.7669 |     0.6811 |\n",
      "\n",
      "\n",
      "SELECT ( COCKTAILS DEFAULT) VS (TREE) ON MY (35)\n",
      "|                |   cocktails_default |   cocktails_random |   hgbt |   logistic |\n",
      "|:---------------|--------------------:|-------------------:|-------:|-----------:|\n",
      "| ACC Mean Rank  |              2.5714 |             2.2424 | 1.9714 |     3.1143 |\n",
      "| ACC Mean Score |              0.8021 |             0.8062 | 0.8053 |     0.7716 |\n",
      "\n",
      "\n",
      "SELECT ( COCKTAILS DEFAULT) VS (LOGREG) ON MY (11)\n",
      "|                |   cocktails_default |   cocktails_random |   hgbt |   logistic |\n",
      "|:---------------|--------------------:|-------------------:|-------:|-----------:|\n",
      "| ACC Mean Rank  |              2.0909 |             2.4    | 1.5455 |     3.8182 |\n",
      "| ACC Mean Score |              0.817  |             0.8149 | 0.8214 |     0.702  |\n",
      "\n",
      "\n",
      "SELECT (HGBT) VS (TREE) ON MY (43)\n",
      "|                |   cocktails_default |   cocktails_random |   hgbt |   logistic |\n",
      "|:---------------|--------------------:|-------------------:|-------:|-----------:|\n",
      "| ACC Mean Rank  |              2.7442 |             2.2927 | 1.814  |     3.0698 |\n",
      "| ACC Mean Score |              0.7711 |             0.7782 | 0.7839 |     0.7493 |\n",
      "\n",
      "\n",
      "SELECT (HGBT) VS (LOGREG) ON MY (18)\n",
      "|                |   cocktails_default |   cocktails_random |   hgbt |   logistic |\n",
      "|:---------------|--------------------:|-------------------:|-------:|-----------:|\n",
      "| ACC Mean Rank  |              2.5    |             2.2778 | 1.3889 |     3.8333 |\n",
      "| ACC Mean Score |              0.7878 |             0.7788 | 0.81   |     0.7145 |\n",
      "\n",
      "\n",
      "SELECT (HGBT) VS (TREE,LOGREG) ON MY (14)\n",
      "|                |   cocktails_default |   cocktails_random |   hgbt |   logistic |\n",
      "|:---------------|--------------------:|-------------------:|-------:|-----------:|\n",
      "| ACC Mean Rank  |              2.4286 |             2.2857 | 1.5    |     3.7857 |\n",
      "| ACC Mean Score |              0.7691 |             0.7627 | 0.7839 |     0.6926 |\n"
     ]
    }
   ],
   "source": [
    "methods = [ \"hgbt\", \"logistic\", \"cocktails_random\", \"cocktails_default\"] # , \"resnet\", \"rf\", \"tree\", \"mlp\",]\n",
    "metrics = [\"acc\"]\n",
    "for key in ranks_df:\n",
    "    current_result = get_result(methods, metrics, ranks_df[key]['dids'], all_my_results.reset_index())\n",
    "    current_ranks = get_average_rank_table(current_result)\n",
    "    ranks_df[key]['ranks'] = current_ranks\n",
    "    print(f\"\\n\\n{key.upper().replace('_', ' ')} ({len(ranks_df[key]['dids'])})\")\n",
    "    pprint(current_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SELECT (HGBT, COCKTAILS DEFAULT) VS (LOGREG) ON MY (19)\n",
      "|                |   cocktails_default |   cocktails_random |   hgbt |   logistic |    mlp |   resnet |     rf |   tree |\n",
      "|:---------------|--------------------:|-------------------:|-------:|-----------:|-------:|---------:|-------:|-------:|\n",
      "| ACC Mean Rank  |              4.4211 |             4.2222 | 1.9474 |     7.2632 | 4.1579 |   5.0526 | 2.2632 | 6.4737 |\n",
      "| ACC Mean Score |              0.7771 |             0.7788 | 0.7952 |     0.7042 | 0.7666 |   0.7531 | 0.7909 | 0.7312 |\n",
      "\n",
      "\n",
      "SELECT (HGBT, COCKTAILS DEFAULT) VS (TREE) ON MY (44)\n",
      "|                |   cocktails_default |   cocktails_random |   hgbt |   logistic |    mlp |   resnet |     rf |   tree |\n",
      "|:---------------|--------------------:|-------------------:|-------:|-----------:|-------:|---------:|-------:|-------:|\n",
      "| ACC Mean Rank  |              4.7273 |             3.878  | 2.75   |     5.3636 | 3.6591 |   4.4545 | 3.2727 | 7.6136 |\n",
      "| ACC Mean Score |              0.7668 |             0.7782 | 0.7781 |     0.7441 | 0.7663 |   0.7644 | 0.7714 | 0.7035 |\n",
      "\n",
      "\n",
      "SELECT (HGBT, COCKTAILS DEFAULT) VS (TREE,LOGREG) ON MY (15)\n",
      "|                |   cocktails_default |   cocktails_random |   hgbt |   logistic |    mlp |   resnet |     rf |   tree |\n",
      "|:---------------|--------------------:|-------------------:|-------:|-----------:|-------:|---------:|-------:|-------:|\n",
      "| ACC Mean Rank  |              4.2    |             4      | 2      |     7.1333 | 4.2    |   4.8    | 2.4    | 7      |\n",
      "| ACC Mean Score |              0.7567 |             0.7627 | 0.7669 |     0.6811 | 0.7404 |   0.7424 | 0.7612 | 0.6941 |\n",
      "\n",
      "\n",
      "SELECT ( COCKTAILS DEFAULT) VS (TREE) ON MY (35)\n",
      "|                |   cocktails_default |   cocktails_random |   hgbt |   logistic |    mlp |   resnet |     rf |   tree |\n",
      "|:---------------|--------------------:|-------------------:|-------:|-----------:|-------:|---------:|-------:|-------:|\n",
      "| ACC Mean Rank  |              4.4286 |             3.697  | 3.1429 |     5.4857 | 3.5143 |   4.3714 | 3.3714 | 7.7429 |\n",
      "| ACC Mean Score |              0.8021 |             0.8062 | 0.8053 |     0.7716 | 0.7967 |   0.7953 | 0.8002 | 0.7275 |\n",
      "\n",
      "\n",
      "SELECT ( COCKTAILS DEFAULT) VS (LOGREG) ON MY (11)\n",
      "|                |   cocktails_default |   cocktails_random |   hgbt |   logistic |    mlp |   resnet |     rf |   tree |\n",
      "|:---------------|--------------------:|-------------------:|-------:|-----------:|-------:|---------:|-------:|-------:|\n",
      "| ACC Mean Rank  |              3.5455 |             4.6    | 2.2727 |     7.7273 | 4.2727 |   4.8182 | 2.3636 | 6.0909 |\n",
      "| ACC Mean Score |              0.817  |             0.8149 | 0.8214 |     0.702  | 0.7892 |   0.7705 | 0.8187 | 0.7636 |\n",
      "\n",
      "\n",
      "SELECT (HGBT) VS (TREE) ON MY (43)\n",
      "|                |   cocktails_default |   cocktails_random |   hgbt |   logistic |    mlp |   resnet |     rf |   tree |\n",
      "|:---------------|--------------------:|-------------------:|-------:|-----------:|-------:|---------:|-------:|-------:|\n",
      "| ACC Mean Rank  |              4.814  |             3.878  | 2.6977 |     5.3256 | 3.6744 |   4.4651 | 3.3023 | 7.6512 |\n",
      "| ACC Mean Score |              0.7711 |             0.7782 | 0.7839 |     0.7493 | 0.7716 |   0.7698 | 0.7762 | 0.7077 |\n",
      "\n",
      "\n",
      "SELECT (HGBT) VS (LOGREG) ON MY (18)\n",
      "|                |   cocktails_default |   cocktails_random |   hgbt |   logistic |    mlp |   resnet |     rf |   tree |\n",
      "|:---------------|--------------------:|-------------------:|-------:|-----------:|-------:|---------:|-------:|-------:|\n",
      "| ACC Mean Rank  |              4.6111 |             4.2222 | 1.7778 |     7.2778 | 4.2222 |   5.1111 | 2.2778 | 6.5    |\n",
      "| ACC Mean Score |              0.7878 |             0.7788 | 0.81   |     0.7145 | 0.7795 |   0.7653 | 0.8035 | 0.7428 |\n",
      "\n",
      "\n",
      "SELECT (HGBT) VS (TREE,LOGREG) ON MY (14)\n",
      "|                |   cocktails_default |   cocktails_random |   hgbt |   logistic |    mlp |   resnet |     rf |   tree |\n",
      "|:---------------|--------------------:|-------------------:|-------:|-----------:|-------:|---------:|-------:|-------:|\n",
      "| ACC Mean Rank  |              4.4286 |             4      | 1.7857 |     7.1429 | 4.2857 |   4.8571 | 2.4286 | 7.0714 |\n",
      "| ACC Mean Score |              0.7691 |             0.7627 | 0.7839 |     0.6926 | 0.7551 |   0.7574 | 0.7752 | 0.7064 |\n"
     ]
    }
   ],
   "source": [
    "methods = [ \"hgbt\", \"logistic\", \"resnet\", \"rf\", \"tree\", \"mlp\", \"cocktails_default\", \"cocktails_random\"]\n",
    "metrics = [\"acc\"]\n",
    "for key in ranks_df:\n",
    "    current_result = get_result(methods, metrics, ranks_df[key]['dids'], all_my_results.reset_index())\n",
    "    current_ranks = get_average_rank_table(current_result)\n",
    "    ranks_df[key]['ranks'] = current_ranks\n",
    "    print(f\"\\n\\n{key.upper().replace('_', ' ')} ({len(ranks_df[key]['dids'])})\")\n",
    "    pprint(current_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [ \"hgbt\", \"linear\", \"resnet\", \"rf\", \"tree\", \"mlp\", \"cocktails_default\", \"cocktails_random\"]\n",
    "\n",
    "too_easy_std_methods_dids, select_std_methods_dids = get_too_easy_select_acc_to_difference(all_my_results, methods=methods)\n",
    "# subset_methods = [ \"hgbt\", \"linear\", \"rf\", \"tree\", \"mlp\",\"autopytorch_default\", \"cocktails_default\"]\n",
    "\n",
    "# too_easy_autopytorch_default_linear_dids, select_autopytorch_default_linear_dids = get_too_easy_select_acc_to_difference(all_my_results, methods=methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "STD > 0.05, METHODS=ALL - RANDOM (SELECT) (5)\n",
      "|                |   cocktails_default |   cocktails_random |   hgbt |   logistic |    mlp |   resnet |     rf |   tree |\n",
      "|:---------------|--------------------:|-------------------:|-------:|-----------:|-------:|---------:|-------:|-------:|\n",
      "| ACC Mean Rank  |              3      |             3.2    | 3      |     6.2    | 4.4    |   5.2    | 4.2    | 6.8    |\n",
      "| ACC Mean Score |              0.8715 |             0.8391 | 0.8596 |     0.7252 | 0.8274 |   0.7868 | 0.8338 | 0.7475 |\n"
     ]
    }
   ],
   "source": [
    "methods = [ \"hgbt\", \"linear\", \"resnet\", \"rf\", \"tree\", \"mlp\", \"cocktails_default\"]\n",
    "\n",
    "too_easy_std_methods_dids, select_std_methods_dids = get_too_easy_select_acc_to_difference(all_my_results, methods=methods)\n",
    "\n",
    "ranks_df = {\n",
    "    \"std_>_0.05,_methods=all_-_random_(select)\": {\n",
    "        \"ranks\": None,\n",
    "        \"dids\": select_std_methods_dids},\n",
    "        }\n",
    "methods = [ \"hgbt\", \"logistic\", \"resnet\", \"rf\", \"tree\", \"mlp\",\"cocktails_default\", \"cocktails_random\"]\n",
    "metrics = [\"acc\"]\n",
    "for key in ranks_df:\n",
    "    current_result = get_result(methods, metrics, ranks_df[key]['dids'], all_my_results.reset_index())\n",
    "    current_ranks = get_average_rank_table(current_result)\n",
    "    ranks_df[key]['ranks'] = current_ranks\n",
    "    print(f\"\\n\\n{key.upper().replace('_', ' ')} ({len(ranks_df[key]['dids'])})\")\n",
    "    pprint(current_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "STD > 0.05, METHODS=HGBT,LINEAR,TREE,COCKTAILS DEFAULT (SELECT) (9)\n",
      "|                |   cocktails_default |   cocktails_random |   hgbt |   logistic |    mlp |   resnet |     rf |   tree |\n",
      "|:---------------|--------------------:|-------------------:|-------:|-----------:|-------:|---------:|-------:|-------:|\n",
      "| ACC Mean Rank  |              3.7778 |             3.3333 | 3.1111 |     5.8889 | 4.3333 |   5      | 4      | 6.5556 |\n",
      "| ACC Mean Score |              0.8739 |             0.8488 | 0.8743 |     0.7723 | 0.8457 |   0.8237 | 0.8567 | 0.7779 |\n"
     ]
    }
   ],
   "source": [
    "methods = [ \"hgbt\", \"linear\", \"tree\", \"cocktails_default\"] # , \"\"]\n",
    "\n",
    "too_easy_std_methods_dids, select_std_methods_dids = get_too_easy_select_acc_to_difference(all_my_results, methods=methods)\n",
    "\n",
    "ranks_df = {\n",
    "    \"std_>_0.05,_methods=hgbt,linear,tree,cocktails_default_(select)\": {\n",
    "        \"ranks\": None,\n",
    "        \"dids\": select_std_methods_dids},\n",
    "        }\n",
    "methods = [ \"hgbt\", \"logistic\", \"resnet\", \"rf\", \"tree\", \"mlp\", \"cocktails_default\", \"cocktails_random\"]\n",
    "metrics = [\"acc\"]\n",
    "for key in ranks_df:\n",
    "    current_result = get_result(methods, metrics, ranks_df[key]['dids'], all_my_results.reset_index())\n",
    "    current_ranks = get_average_rank_table(current_result)\n",
    "    ranks_df[key]['ranks'] = current_ranks\n",
    "    print(f\"\\n\\n{key.upper().replace('_', ' ')} ({len(ranks_df[key]['dids'])})\")\n",
    "    pprint(current_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electricity\n",
      "covertype\n",
      "poker\n",
      "pol\n",
      "elevators\n",
      "phoneme\n",
      "twonorm\n",
      "Indian_pines\n",
      "SantanderCustomerSatisfaction\n"
     ]
    }
   ],
   "source": [
    "import openml\n",
    "for d_id in select_std_methods_dids:\n",
    "    dataset = openml.datasets.get_dataset(dataset_id=d_id, download_data=False)\n",
    "    print(dataset.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SELECT THEIR BENCHMARK (12)\n",
      "|                |   cocktails_default |   cocktails_random |   hgbt |   logistic |    mlp |   resnet |     rf |   tree |\n",
      "|:---------------|--------------------:|-------------------:|-------:|-----------:|-------:|---------:|-------:|-------:|\n",
      "| ACC Mean Rank  |              4.9167 |             4      | 1.9167 |     7.25   | 4.1667 |   5.1667 | 2.25   | 6.3333 |\n",
      "| ACC Mean Score |              0.8021 |             0.8037 | 0.8369 |     0.7405 | 0.8067 |   0.7843 | 0.8345 | 0.7757 |\n"
     ]
    }
   ],
   "source": [
    "their_datasets = [151, 293, 722, 821, 993, 1044, 1120, 1461, 1489, 41150, 41168, 42769]\n",
    "\n",
    "ranks_df = {\n",
    "    \"select_their_benchmark\": {\n",
    "        \"ranks\": None,\n",
    "        \"dids\": their_datasets},\n",
    "        }\n",
    "methods = [ \"hgbt\", \"logistic\", \"resnet\", \"rf\", \"tree\", \"mlp\", \"cocktails_default\", \"cocktails_random\"]\n",
    "metrics = [\"acc\"]\n",
    "for key in ranks_df:\n",
    "    current_result = get_result(methods, metrics, ranks_df[key]['dids'], all_my_results.reset_index())\n",
    "    current_ranks = get_average_rank_table(current_result)\n",
    "    ranks_df[key]['ranks'] = current_ranks\n",
    "    print(f\"\\n\\n{key.upper().replace('_', ' ')} ({len(ranks_df[key]['dids'])})\")\n",
    "    pprint(current_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "STD > 0.05, METHODS=HGBT,LINEAR,TREE,RESNET MLP RF (SELECT) (7)\n",
      "|                |   cocktails_default |   cocktails_random |   hgbt |   logistic |    mlp |   resnet |     rf |   tree |\n",
      "|:---------------|--------------------:|-------------------:|-------:|-----------:|-------:|---------:|-------:|-------:|\n",
      "| ACC Mean Rank  |              3.5714 |             3.5714 | 3      |     5.7143 | 4.2857 |   5.1429 | 3.8571 | 6.8571 |\n",
      "| ACC Mean Score |              0.8829 |             0.8486 | 0.8773 |     0.7629 | 0.8495 |   0.8216 | 0.8601 | 0.7732 |\n"
     ]
    }
   ],
   "source": [
    "methods = [ \"hgbt\", \"linear\", \"tree\", \"resnet\", \"mlp\", \"rf\"] # , \"\"]\n",
    "\n",
    "too_easy_std_methods_dids, select_std_methods_dids = get_too_easy_select_acc_to_difference(all_my_results, methods=methods)\n",
    "\n",
    "ranks_df = {\n",
    "    \"std_>_0.05,_methods=hgbt,linear,tree,resnet_mlp_rf_(select)\": {\n",
    "        \"ranks\": None,\n",
    "        \"dids\": select_std_methods_dids},\n",
    "        }\n",
    "methods = [ \"hgbt\", \"logistic\", \"resnet\", \"rf\", \"tree\", \"mlp\", \"cocktails_default\", \"cocktails_random\"]\n",
    "metrics = [\"acc\"]\n",
    "for key in ranks_df:\n",
    "    current_result = get_result(methods, metrics, ranks_df[key]['dids'], all_my_results.reset_index())\n",
    "    current_ranks = get_average_rank_table(current_result)\n",
    "    ranks_df[key]['ranks'] = current_ranks\n",
    "    print(f\"\\n\\n{key.upper().replace('_', ' ')} ({len(ranks_df[key]['dids'])})\")\n",
    "    pprint(current_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covertype\n",
      "poker\n",
      "pol\n",
      "phoneme\n",
      "twonorm\n",
      "Indian_pines\n",
      "SantanderCustomerSatisfaction\n"
     ]
    }
   ],
   "source": [
    "import openml\n",
    "for d_id in select_std_methods_dids:\n",
    "    dataset = openml.datasets.get_dataset(dataset_id=d_id, download_data=False)\n",
    "    print(dataset.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "STD > 0.05, METHODS=HGBT,RESNET MLP RF (SELECT) (3)\n",
      "|                |   cocktails_default |   cocktails_random |   hgbt |   logistic |    mlp |   resnet |     rf |   tree |\n",
      "|:---------------|--------------------:|-------------------:|-------:|-----------:|-------:|---------:|-------:|-------:|\n",
      "| ACC Mean Rank  |              5.3333 |             3.3333 | 1.6667 |     7.6667 | 4      |   6.6667 | 2.6667 | 4.6667 |\n",
      "| ACC Mean Score |              0.7683 |             0.8567 | 0.837  |     0.7169 | 0.7875 |   0.6894 | 0.8291 | 0.7911 |\n"
     ]
    }
   ],
   "source": [
    "methods = [ \"hgbt\",  \"resnet\", \"mlp\"] # , \"\"]\n",
    "\n",
    "too_easy_std_methods_dids, select_std_methods_dids = get_too_easy_select_acc_to_difference(all_my_results, methods=methods)\n",
    "\n",
    "ranks_df = {\n",
    "    \"std_>_0.05,_methods=hgbt,resnet_mlp_rf_(select)\": {\n",
    "        \"ranks\": None,\n",
    "        \"dids\": select_std_methods_dids},\n",
    "        }\n",
    "methods = [ \"hgbt\", \"logistic\", \"resnet\", \"rf\", \"tree\", \"mlp\", \"cocktails_default\", \"cocktails_random\"]\n",
    "metrics = [\"acc\"]\n",
    "for key in ranks_df:\n",
    "    current_result = get_result(methods, metrics, ranks_df[key]['dids'], all_my_results.reset_index())\n",
    "    current_ranks = get_average_rank_table(current_result)\n",
    "    ranks_df[key]['ranks'] = current_ranks\n",
    "    print(f\"\\n\\n{key.upper().replace('_', ' ')} ({len(ranks_df[key]['dids'])})\")\n",
    "    pprint(current_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('tab_bench-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bdd89d8741d58698331340ea54180aeeb25ca9f979bf53364921e9917b5aca39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
