,mean_r2_test,mean_r2_val,mean_time,...7,_runtime,_step,_timestamp,data__categorical,data__regression,data_generation_time,max_test_samples,max_test_score,max_train_samples,max_train_score,max_val_samples,max_val_score,mean_r2_train,mean_test_score,mean_train_score,mean_val_score,min_test_score,min_train_score,min_val_score,n_features,n_test,n_train,one_hot_encoder,regression,std_r2_test,std_r2_train,std_r2_val,std_test_score,std_time,std_train_score,std_val_score,step,train_prop,transformed_target,val_test_prop,model__learning_rate,model__max_depth,model__max_leaf_nodes,model__min_impurity_decrease,model__min_samples_leaf,model__min_samples_split,model__n_estimators,model__n_iter_no_change,model__subsample,model__validation_fraction,early_stopping_rounds,model__colsample_bylevel,model__colsample_bytree,model__gamma,model__min_child_weight,model__reg_alpha,model__reg_lambda,model__use_label_encoder,model__early_stopping,model__max_iter,model__bootstrap,Unnamed: 0,log_training,model__batch_size,model__lr,model__lr_scheduler,model__max_epochs,model__module__d_embedding,model__module__d_layers,model__module__dropout,model__module__n_layers,model__use_checkpoints,num_epochs,model__module__d,model__module__d_hidden_factor,model__module__hidden_dropout,model__module__residual_dropout,model__optimizer__weight_decay,d_token,model__module__attention_dropout,model__module__d_ffn_factor,model__module__d_token,model__module__ffn_dropout,model__module__kv_compression,model__module__n_heads,model__module__prenormalization,model__module__token_bias,model__args__batch_size,model__args__data_parallel,model__args__early_stopping_rounds,model__args__epochs,model__args__lr,model__args__num_classes,model__args__use_gpu,model__args__val_batch_size,model__params__depth,model__params__dim,model__params__dropout,model__params__heads,...129,Tags,Runtime,data__n_features,data__n_samples,data__num_samples,model__clf_loss,model__module_d_token,model__n_features_per_subset,model__rotation_algo,model__wandb_run,model__weight_decay,model_module__initialization,model_module__prenormalization,target__method_name,target__n_periods,target__noise,target__period,target__period_size,train_set_prop,transform__0__max_rel_decrease,transform__0__multiplier,transform__1__method_name,transform__1__multiplier,transform__1__type,transform__2__method_name,transform__2__type,test_score,train_score,...165,transform__0__n_iter,transform__1__num_features,transform__2__cov_mult,transform__2__covariance_estimation,transform__2__deactivated,...171,...172,model__alpha,model__class_weight,transform__0__model_to_use,transform__0__num_features_to_remove,transform__0__keep_removed_features,transform__1__max_rel_decrease,transform__1__n_iter,...180,...181,...1
count,0.0,0.0,254.0,0.0,254.0,254.0,254.0,254.0,254.0,254.0,254.0,254.0,254.0,254.0,254.0,254.0,0.0,254.0,254.0,254.0,254.0,254.0,254.0,254.0,254.0,254.0,254.0,254.0,0.0,0.0,0.0,254.0,254.0,254.0,254.0,254.0,254.0,254.0,254.0,0.0,74.0,0.0,254.0,254.0,254.0,254.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,254.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,254.0,0.0
mean,,,1.000496000192297,,8.39763779527559,0.0,1660940778.5866141,0.0,0.0,0.0011870081969133216,50000.0,0.7672326573703426,10000.0,0.8479019515397732,50000.0,0.7810338925025676,,0.7523174826610362,0.8423033368730419,0.7607497432386169,0.7347175178521679,0.8370294647696178,0.735535775419377,11.0,537.0,1787.0,1.0,0.0,,,,0.011753630779783529,0.04210056293912165,0.0039569403370892575,0.01675047363991935,4780.885826771653,0.7000000000000001,0.41338582677165353,0.29999999999999993,,3.0405405405405403,,0.0052362204724409455,13.649606299212598,2.059055118110236,250.0,,,,,,,,,,,,,,0.49606299212598426,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4186.102362204724,
std,,,0.6060446733442885,,3.023516905357872,0.0,6662.9258281390585,0.0,0.0,0.001811836889683513,0.0,0.03200827912868274,0.0,0.09421277479249965,0.0,0.036001454855353,,0.030631088750742143,0.09606244440042258,0.029011843420094496,0.03173692699019872,0.0977639917566066,0.020939723455842486,0.0,0.0,0.0,0.0,0.0,,,,0.003195581021680233,0.017423080183467145,0.002565036783375266,0.008099059769149519,1102.090352473751,1.1124149774493831e-16,0.493413087640815,5.562074887246916e-17,,0.8348437502760899,,0.013147961078447476,12.814242163153018,0.23619323860314823,0.0,,,,,,,,,,,,,,0.5009716369182445,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1102.0727889610155,
min,,,0.381099271774292,,5.0,0.0,1660930276.0,0.0,0.0,0.00063920021057128,50000.0,0.7057728119180633,10000.0,0.7229994404029099,50000.0,0.7260869565217392,,0.6960893854748603,0.7174034695019585,0.7069565217391305,0.659217877094972,0.6994963626189143,0.6782608695652174,11.0,537.0,1787.0,1.0,0.0,,,,0.0038344991214103,0.0147343114918624,0.0,0.0017391304347825,2953.0,0.7,0.0,0.3,,2.0,,0.0,2.0,2.0,250.0,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2061.0,
25%,,,0.5793034791946411,,6.0,0.0,1660934665.0,0.0,0.0,0.0009106397628784125,50000.0,0.7411545623836127,10000.0,0.7683268047006155,50000.0,0.7478260869565218,,0.7247672253258844,0.7580861779518746,0.7330434782608697,0.7039106145251397,0.7504196978175713,0.7217391304347827,11.0,537.0,1787.0,1.0,0.0,,,,0.009557212909713375,0.03311680032312975,0.0020145495243424,0.010214285080232925,3831.0,0.7,0.0,0.3,,2.0,,0.0,3.0,2.0,250.0,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3256.25,
50%,,,0.8092020511627197,,7.0,0.0,1660940529.5,0.0,0.0,0.00103735923767085,50000.0,0.770949720670391,10000.0,0.8172915500839395,50000.0,0.7782608695652173,,0.752513966480447,0.8110240626748741,0.7595652173913043,0.7355679702048417,0.8047006155567991,0.7391304347826086,11.0,537.0,1787.0,1.0,0.0,,,,0.0116651090576986,0.03703449992055485,0.0036950299341717502,0.01523583158079205,4755.5,0.7,0.0,0.3,,3.0,,0.0,8.0,2.0,250.0,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4211.0,
75%,,,1.2049506545066833,,9.75,0.0,1660946458.5,0.0,0.0,0.0012210607528686502,50000.0,0.7946927374301676,10000.0,0.9324286513710129,50000.0,0.8130434782608695,,0.7797951582867784,0.9228875209848909,0.7843478260869566,0.7630353817504656,0.9187185226636823,0.7478260869565218,11.0,537.0,1787.0,1.0,0.0,,,,0.013840456241999026,0.04425307405349415,0.005386066003720675,0.023259849433333174,5710.75,0.7,1.0,0.3,,4.0,,0.0,20.0,2.0,250.0,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5136.0,
max,,,3.61239628791809,,21.0,0.0,1660953808.0,0.0,0.0,0.0296258926391601,50000.0,0.8361266294227188,10000.0,1.0,50000.0,0.8521739130434782,,0.8048417132216017,1.0,0.8147826086956522,0.7895716945996276,1.0,0.7869565217391304,11.0,537.0,1787.0,1.0,0.0,,,,0.0204197395335162,0.1617014044771706,0.0134954585741312,0.0377435381116707,6906.0,0.7,1.0,0.3,,4.0,,0.05,50.0,3.0,250.0,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,6014.0,
